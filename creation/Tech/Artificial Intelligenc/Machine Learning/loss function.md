It's a method of evaluating how well a model is suited or trained for the intended task.

A loss function quantifies the error between the output of a [[neural network]] and intended output.

If the prediction of a model is completely off, the loss function will output a higher number. If the prediction is fairly accurate, the loss function will output a lower number.

It serves as a gauge to tell if our [[neural network]] is improving or not.

Some types of loss functions include
- [[mean squared error]]
- [[binary cross entropy]]
- [[huber loss]]