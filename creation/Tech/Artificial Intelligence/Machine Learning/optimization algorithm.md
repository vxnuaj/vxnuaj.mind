---
Last Updated: 02-21-2024 | 2:00
---
An optimization algorithm is an algorithm used to train [[deep learning]] models, allowing to update the model parameters to minimize the value of the [[loss function]] through [[backpropagation]].

It iteratively adjusts the parameters of the model to optimize for a specific objective, which in the case of [[deep learning]] is to output an accurate result, until a set of parameters that's optimal for minimizing the [[loss function]] is found.

Choosing the appropriate optimization algorithm is important as it can directly effect the training speed and efficiency as well as the accuracy of the model.

**Optimization algorithms:**
- [[gradient descent]]
- [[Stochastic Gradient Descent]]
- [[Adam]]